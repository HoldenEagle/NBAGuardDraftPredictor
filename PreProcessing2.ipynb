{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5052b4-4157-438e-8b9f-0d9d5932ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframe\n",
    "import pandas as pd\n",
    "\n",
    "combine_df = pd.read_csv(\"draft_combine_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc67605-9612-4022-966b-9a46eb7796ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>player_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>player_name</th>\n",
       "      <th>position</th>\n",
       "      <th>height_wo_shoes</th>\n",
       "      <th>weight</th>\n",
       "      <th>wingspan</th>\n",
       "      <th>standing_reach</th>\n",
       "      <th>body_fat_pct</th>\n",
       "      <th>hand_length</th>\n",
       "      <th>hand_width</th>\n",
       "      <th>standing_vertical_leap</th>\n",
       "      <th>max_vertical_leap</th>\n",
       "      <th>lane_agility_time</th>\n",
       "      <th>modified_lane_agility_time</th>\n",
       "      <th>three_quarter_sprint</th>\n",
       "      <th>bench_press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>12033</td>\n",
       "      <td>Adam</td>\n",
       "      <td>Allenspach</td>\n",
       "      <td>Adam Allenspach</td>\n",
       "      <td>C</td>\n",
       "      <td>83.50</td>\n",
       "      <td>259.0</td>\n",
       "      <td>84.5</td>\n",
       "      <td>107.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.40</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>2240</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Arenas</td>\n",
       "      <td>Gilbert Arenas</td>\n",
       "      <td>SG</td>\n",
       "      <td>74.25</td>\n",
       "      <td>199.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>99.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.5</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.25</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001</td>\n",
       "      <td>2220</td>\n",
       "      <td>Brandon</td>\n",
       "      <td>Armstrong</td>\n",
       "      <td>Brandon Armstrong</td>\n",
       "      <td>SG</td>\n",
       "      <td>75.50</td>\n",
       "      <td>188.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>99.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.20</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>2203</td>\n",
       "      <td>Shane</td>\n",
       "      <td>Battier</td>\n",
       "      <td>Shane Battier</td>\n",
       "      <td>SF-PF</td>\n",
       "      <td>80.25</td>\n",
       "      <td>229.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>105.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.5</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.30</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>12034</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>Belcher</td>\n",
       "      <td>Cookie Belcher</td>\n",
       "      <td>SG-PG</td>\n",
       "      <td>75.00</td>\n",
       "      <td>206.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>11.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.91</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  player_id first_name   last_name        player_name position  \\\n",
       "0  2001      12033       Adam  Allenspach    Adam Allenspach        C   \n",
       "1  2001       2240    Gilbert      Arenas     Gilbert Arenas       SG   \n",
       "2  2001       2220    Brandon   Armstrong  Brandon Armstrong       SG   \n",
       "3  2001       2203      Shane     Battier      Shane Battier    SF-PF   \n",
       "4  2001      12034     Cookie     Belcher     Cookie Belcher    SG-PG   \n",
       "\n",
       "   height_wo_shoes  weight  wingspan  standing_reach  body_fat_pct  \\\n",
       "0            83.50   259.0      84.5           107.0          12.4   \n",
       "1            74.25   199.0      81.5            99.5           5.3   \n",
       "2            75.50   188.0      81.5            99.5           9.3   \n",
       "3            80.25   229.0      82.5           105.0           9.3   \n",
       "4            75.00   206.0      80.5            99.0           5.3   \n",
       "\n",
       "   hand_length  hand_width  standing_vertical_leap  max_vertical_leap  \\\n",
       "0          NaN         NaN                    28.5               31.0   \n",
       "1          NaN         NaN                    31.5               36.0   \n",
       "2          NaN         NaN                    30.0               37.0   \n",
       "3          NaN         NaN                    29.5               33.0   \n",
       "4          NaN         NaN                    35.0               41.5   \n",
       "\n",
       "   lane_agility_time  modified_lane_agility_time  three_quarter_sprint  \\\n",
       "0              11.90                         NaN                  3.40   \n",
       "1                NaN                         NaN                  3.25   \n",
       "2              10.91                         NaN                  3.20   \n",
       "3              10.95                         NaN                  3.30   \n",
       "4              11.26                         NaN                  2.91   \n",
       "\n",
       "   bench_press  \n",
       "0         16.0  \n",
       "1         12.0  \n",
       "2          6.0  \n",
       "3         12.0  \n",
       "4          7.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove player_id , height_w_shoes , height_w_shoes_ft_in , height_wo_shoes_ft_in\n",
    "combine_df.drop(columns = ['height_wo_shoes_ft_in' , 'height_w_shoes' , 'height_w_shoes_ft_in' , 'wingspan_ft_in' , 'standing_reach_ft_in',\n",
    "                          'spot_nba_break_right' , 'spot_nba_corner_right' , 'off_drib_fifteen_top_key' , 'off_drib_fifteen_break_right' , 'off_drib_college_break_left',\n",
    "                          'off_drib_college_top_key' , 'off_drib_college_break_right' , 'on_move_fifteen', 'on_move_college' , 'spot_fifteen_corner_right',\n",
    "                          'spot_college_corner_left' , 'spot_college_break_left', 'spot_college_top_key' , 'spot_college_break_right' , 'spot_college_corner_right', \n",
    "                          'spot_nba_corner_left' , 'spot_nba_break_left' , 'spot_nba_top_key' , 'off_drib_fifteen_break_left' , 'spot_fifteen_corner_left' , 'spot_fifteen_break_left' ,\n",
    "                          'spot_fifteen_top_key', 'spot_fifteen_break_right'], inplace= True)\n",
    "combine_df.rename(columns={'season': 'year'}, inplace=True)\n",
    "combine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bfb417-484b-481e-89f3-59ca8c41273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year\n",
      "2022    83\n",
      "2023    81\n",
      "2004    81\n",
      "2005    81\n",
      "2001    78\n",
      "2019    77\n",
      "2007    77\n",
      "2008    76\n",
      "2018    69\n",
      "2017    64\n",
      "2013    63\n",
      "2012    61\n",
      "2015    58\n",
      "2014    56\n",
      "2011    54\n",
      "2010    52\n",
      "2009    46\n",
      "2020    45\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#combine_df = combine_df[(combine_df['season'] >= 2009) & (combine_df['season'] <= 2021)]\n",
    "print(combine_df['year'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99688f94-2dd0-4d3d-ab86-a7242d065de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player_name', 'team', 'conf', 'GP', 'Min_per', 'Ortg', 'usg', 'eFG',\n",
      "       'TS_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FTM', 'FTA',\n",
      "       'FT_per', 'twoPM', 'twoPA', 'twoP_per', 'TPM', 'TPA', 'TP_per',\n",
      "       'blk_per', 'stl_per', 'ftr', 'yr', 'ht', 'num', 'porpag', 'adjoe',\n",
      "       'pfr', 'year', 'pid', 'type', 'Rec Rank', 'ast/tov', 'rimmade',\n",
      "       'rimmade+rimmiss', 'midmade', 'midmade+midmiss',\n",
      "       'rimmade/(rimmade+rimmiss)', 'midmade/(midmade+midmiss)', 'dunksmade',\n",
      "       'dunksmiss+dunksmade', 'dunksmade/(dunksmade+dunksmiss)', 'pick',\n",
      "       'drtg', 'adrtg', 'dporpag', 'stops', 'bpm', 'obpm', 'dbpm', 'gbpm',\n",
      "       'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', 'ast', 'stl', 'blk',\n",
      "       'pts', 'Role/Position', 'Unnamed: 65', 'team_encoded', 'conf_encoded',\n",
      "       'yr_encoded', 'ht_encoded', 'got_drafted', 'Role/Position_encoded',\n",
      "       'Drafted_that_year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\37651004.py:6: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ncaa_df = pd.read_csv(\"NCAA_Stats_Preprocessed.csv\")\n"
     ]
    }
   ],
   "source": [
    "#loading data , making dataframe, and label encoding a feature I got to label encode\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "ncaa_df = pd.read_csv(\"NCAA_Stats_Preprocessed.csv\")\n",
    "#pg_df = ncaa_df[\n",
    "    #(ncaa_df['Role/Position'] == 'Scoring PG') | (ncaa_df['Role/Position'] == 'Pure PG')\n",
    "#]\n",
    "pg_df = ncaa_df\n",
    "\n",
    "#print(len(pg_df))\n",
    "pg_df['Role/Position'] = le.fit_transform(pg_df['Role/Position'])\n",
    "\n",
    "pg_df.head()\n",
    "print(pg_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52c8a60-c6e3-4794-b72f-1c88b8738472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player_name', 'team', 'conf', 'GP', 'Min_per', 'Ortg', 'usg', 'eFG',\n",
      "       'TS_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FTM', 'FTA',\n",
      "       'FT_per', 'twoPM', 'twoPA', 'twoP_per', 'TPM', 'TPA', 'TP_per',\n",
      "       'blk_per', 'stl_per', 'ftr', 'yr', 'ht', 'num', 'porpag', 'adjoe',\n",
      "       'pfr', 'year', 'pid', 'type', 'Rec Rank', 'ast/tov', 'rimmade',\n",
      "       'rimmade+rimmiss', 'midmade', 'midmade+midmiss',\n",
      "       'rimmade/(rimmade+rimmiss)', 'midmade/(midmade+midmiss)', 'dunksmade',\n",
      "       'dunksmiss+dunksmade', 'dunksmade/(dunksmade+dunksmiss)', 'pick',\n",
      "       'drtg', 'adrtg', 'dporpag', 'stops', 'bpm', 'obpm', 'dbpm', 'gbpm',\n",
      "       'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', 'ast', 'stl', 'blk',\n",
      "       'pts', 'Role/Position', 'Unnamed: 65', 'team_encoded', 'conf_encoded',\n",
      "       'yr_encoded', 'ht_encoded', 'got_drafted', 'Role/Position_encoded',\n",
      "       'Drafted_that_year', 'player_id', 'first_name', 'last_name', 'position',\n",
      "       'height_wo_shoes', 'weight', 'wingspan', 'standing_reach',\n",
      "       'body_fat_pct', 'hand_length', 'hand_width', 'standing_vertical_leap',\n",
      "       'max_vertical_leap', 'lane_agility_time', 'modified_lane_agility_time',\n",
      "       'three_quarter_sprint', 'bench_press'],\n",
      "      dtype='object')\n",
      "1           Jordan Hill\n",
      "2        Chase Budinger\n",
      "3           Eric Maynor\n",
      "5            Earl Clark\n",
      "6      Dante Cunningham\n",
      "             ...       \n",
      "574        Tyrell Terry\n",
      "575     Cassius Stanley\n",
      "576     Jahmi'us Ramsey\n",
      "577          Josh Green\n",
      "578      Isaiah Stewart\n",
      "Name: player_name, Length: 428, dtype: object\n",
      "428\n"
     ]
    }
   ],
   "source": [
    "#merge the two dataframes\n",
    "merged_df =pd.merge(pg_df, combine_df, on = ['year', 'player_name'] , how='inner')\n",
    "merged_df = merged_df.dropna(subset=['pick'])\n",
    "print(merged_df.columns)\n",
    "print(merged_df['player_name'])\n",
    "print(len(merged_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4608e69-428f-48cb-8d61-29c5b8d4dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player_name', 'team', 'conf', 'GP', 'Min_per', 'Ortg', 'usg', 'eFG',\n",
      "       'TS_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FTM', 'FTA',\n",
      "       'FT_per', 'twoPM', 'twoPA', 'twoP_per', 'TPM', 'TPA', 'TP_per',\n",
      "       'blk_per', 'stl_per', 'ftr', 'yr', 'ht', 'num', 'porpag', 'adjoe',\n",
      "       'pfr', 'year', 'pid', 'type', 'Rec Rank', 'ast/tov', 'rimmade',\n",
      "       'rimmade+rimmiss', 'midmade', 'midmade+midmiss',\n",
      "       'rimmade/(rimmade+rimmiss)', 'midmade/(midmade+midmiss)', 'dunksmade',\n",
      "       'dunksmiss+dunksmade', 'dunksmade/(dunksmade+dunksmiss)', 'pick',\n",
      "       'drtg', 'adrtg', 'dporpag', 'stops', 'bpm', 'obpm', 'dbpm', 'gbpm',\n",
      "       'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', 'ast', 'stl', 'blk',\n",
      "       'pts', 'Role/Position', 'Unnamed: 65', 'team_encoded', 'conf_encoded',\n",
      "       'yr_encoded', 'ht_encoded', 'got_drafted', 'Role/Position_encoded',\n",
      "       'Drafted_that_year', 'player_id', 'first_name', 'last_name', 'position',\n",
      "       'height_wo_shoes', 'weight', 'wingspan', 'standing_reach',\n",
      "       'body_fat_pct', 'hand_length', 'hand_width', 'standing_vertical_leap',\n",
      "       'max_vertical_leap', 'lane_agility_time', 'modified_lane_agility_time',\n",
      "       'three_quarter_sprint', 'bench_press'],\n",
      "      dtype='object')\n",
      "height_wo_shoes\n",
      "False    422\n",
      "True       6\n",
      "Name: count, dtype: int64\n",
      "wingspan\n",
      "False    422\n",
      "True       6\n",
      "Name: count, dtype: int64\n",
      "standing_reach\n",
      "False    422\n",
      "True       6\n",
      "Name: count, dtype: int64\n",
      "standing_vertical_leap\n",
      "False    357\n",
      "True      71\n",
      "Name: count, dtype: int64\n",
      "three_quarter_sprint\n",
      "False    356\n",
      "True      72\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.columns)\n",
    "sub_df = merged_df[['player_name' , 'year' , 'pick']]\n",
    "#print(sub_df.head(20))\n",
    "print(merged_df['height_wo_shoes'].isnull().value_counts())\n",
    "print(merged_df['wingspan'].isnull().value_counts())\n",
    "print(merged_df['standing_reach'].isnull().value_counts())\n",
    "print(merged_df['standing_vertical_leap'].isnull().value_counts())\n",
    "print(merged_df['three_quarter_sprint'].isnull().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32c8152-3aa3-42b6-b792-df447d546c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['height_wo_shoes'] = model_df['height_wo_shoes'].fillna(-1)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['height_wo_shoes_missing'] = model_df['height_wo_shoes'].eq(-1).astype(int)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['three_quarter_sprint'] = model_df['three_quarter_sprint'].fillna(-1)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['three_quarter_sprint_missing'] = model_df['three_quarter_sprint'].eq(-1).astype(int)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['wingspan'] = model_df['wingspan'].fillna(-1)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['wingspan_missing'] = model_df['wingspan'].eq(-1).astype(int)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['standing_reach'] = model_df['standing_reach'].fillna(-1)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['standing_reach_missing'] = model_df['standing_reach'].eq(-1).astype(int)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['max_vertical_leap'] = model_df['max_vertical_leap'].fillna(-1)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['max_vertical_leap_missing'] = model_df['max_vertical_leap'].eq(-1).astype(int)\n",
      "C:\\Users\\holde\\AppData\\Local\\Temp\\ipykernel_15264\\1887266306.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  model_df['missing_combine'] = model_df[missing_cols].sum(axis=1) == len(missing_cols)\n"
     ]
    }
   ],
   "source": [
    "#where we choose the columns\n",
    "model_df = merged_df[['conf_encoded' , 'Rec Rank' , 'Role/Position' , 'adrtg' , 'pts' , 'ast' , 'blk' , 'TPM' , 'height_wo_shoes', 'three_quarter_sprint', 'wingspan', 'standing_reach' , 'max_vertical_leap' , 'pick']]\n",
    "\n",
    "model_df['height_wo_shoes'] = model_df['height_wo_shoes'].fillna(-1)\n",
    "model_df['height_wo_shoes_missing'] = model_df['height_wo_shoes'].eq(-1).astype(int)\n",
    "\n",
    "model_df['three_quarter_sprint'] = model_df['three_quarter_sprint'].fillna(-1)\n",
    "model_df['three_quarter_sprint_missing'] = model_df['three_quarter_sprint'].eq(-1).astype(int)\n",
    "\n",
    "model_df['wingspan'] = model_df['wingspan'].fillna(-1)\n",
    "model_df['wingspan_missing'] = model_df['wingspan'].eq(-1).astype(int)\n",
    "\n",
    "model_df['standing_reach'] = model_df['standing_reach'].fillna(-1)\n",
    "model_df['standing_reach_missing'] = model_df['standing_reach'].eq(-1).astype(int)\n",
    "\n",
    "model_df['max_vertical_leap'] = model_df['max_vertical_leap'].fillna(-1)\n",
    "model_df['max_vertical_leap_missing'] = model_df['max_vertical_leap'].eq(-1).astype(int)\n",
    "\n",
    "missing_cols = [\n",
    "    'height_wo_shoes_missing',\n",
    "    'three_quarter_sprint_missing',\n",
    "    'wingspan_missing',\n",
    "    'standing_reach_missing',\n",
    "    'max_vertical_leap_missing'\n",
    "]\n",
    "\n",
    "model_df['missing_combine'] = model_df[missing_cols].sum(axis=1) == len(missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61d5405b-864b-4278-8f44-8b08dbcc9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement train test split to make a training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = model_df.drop(['pick'], axis=1)\n",
    "y = model_df['pick']\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.15,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1281f-6d51-43e2-9756-8c1f6c39ece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST MODEL:\n",
      " (300, 0.03, 4, 1, 1, 1): Avg RMSE: 14.2467\n",
      "NEW BEST MODEL:\n",
      " (300, 0.03, 4, 1, 1, 0.9): Avg RMSE: 14.0259\n",
      "NEW BEST MODEL:\n",
      " (300, 0.03, 4, 1, 1, 0.8): Avg RMSE: 13.8530\n",
      "NEW BEST MODEL:\n",
      " (300, 0.03, 4, 1, 1, 0.7): Avg RMSE: 13.8205\n",
      "Params: (300, 0.03, 4, 1, 0.9, 1) | Avg RMSE: 14.2281\n",
      "Params: (300, 0.03, 4, 1, 0.9, 0.9) | Avg RMSE: 14.0265\n",
      "NEW BEST MODEL:\n",
      " (300, 0.03, 4, 1, 0.9, 0.8): Avg RMSE: 13.8087\n",
      "NEW BEST MODEL:\n",
      " (300, 0.03, 4, 1, 0.9, 0.7): Avg RMSE: 13.7310\n",
      "Params: (300, 0.03, 4, 1, 0.8, 1) | Avg RMSE: 14.0911\n",
      "Params: (300, 0.03, 4, 1, 0.8, 0.9) | Avg RMSE: 13.9998\n",
      "Params: (300, 0.03, 4, 1, 0.8, 0.8) | Avg RMSE: 13.8820\n",
      "Params: (300, 0.03, 4, 1, 0.8, 0.7) | Avg RMSE: 13.7963\n",
      "Params: (300, 0.03, 4, 3, 1, 1) | Avg RMSE: 13.7616\n",
      "Params: (300, 0.03, 4, 3, 1, 0.9) | Avg RMSE: 13.8540\n",
      "Params: (300, 0.03, 4, 3, 1, 0.8) | Avg RMSE: 13.7468\n",
      "Params: (300, 0.03, 4, 3, 1, 0.7) | Avg RMSE: 13.7733\n",
      "Params: (300, 0.03, 4, 3, 0.9, 1) | Avg RMSE: 13.8055\n",
      "Params: (300, 0.03, 4, 3, 0.9, 0.9) | Avg RMSE: 13.8001\n",
      "Params: (300, 0.03, 4, 3, 0.9, 0.8) | Avg RMSE: 13.7991\n",
      "NEW BEST MODEL:\n",
      " (300, 0.03, 4, 3, 0.9, 0.7): Avg RMSE: 13.7303\n",
      "Params: (300, 0.03, 4, 3, 0.8, 1) | Avg RMSE: 13.9166\n",
      "Params: (300, 0.03, 4, 3, 0.8, 0.9) | Avg RMSE: 13.8204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "possible_estimators = [300, 400 ,500]\n",
    "possible_learning_rate = [.03 , .04 , .05 , .1]\n",
    "possible_max_depth = [4,5,6,7]\n",
    "possible_child_weight = [1,3,4,5]\n",
    "possible_col_sample = [1,.9 , .8]\n",
    "possible_subsample = [1,.9,.8 , .7]\n",
    "\n",
    "kf = KFold(n_splits=7, shuffle=True, random_state=42)\n",
    "\n",
    "best_rmse = float('inf')\n",
    "model_params = None\n",
    "\n",
    "for ne in possible_estimators:\n",
    "    for lr in possible_learning_rate:\n",
    "        for md in possible_max_depth:\n",
    "            for cw in possible_child_weight:\n",
    "                for cs in possible_col_sample:\n",
    "                    for ss in possible_subsample:\n",
    "                        rmses = []\n",
    "                        for train_index, val_index in kf.split(X_train):\n",
    "                            X_tr, X_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "                            y_tr, y_val = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "                            # Scale the target\n",
    "                            scaler = MinMaxScaler()\n",
    "                            y_tr_scaled = scaler.fit_transform(y_tr.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "                            # Train model\n",
    "                            model = xgb.XGBRegressor(\n",
    "                                objective='reg:logistic',\n",
    "                                booster='dart',\n",
    "                                colsample_bytree=cs,\n",
    "                                learning_rate=lr,\n",
    "                                max_depth=md,\n",
    "                                min_child_weight=cw,\n",
    "                                n_estimators=ne,\n",
    "                                subsample=ss,\n",
    "                                random_state=42\n",
    "                            )\n",
    "                            model.fit(X_tr, y_tr_scaled)\n",
    "\n",
    "                            y_pred_scaled = model.predict(X_val)\n",
    "                            y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "                            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "                            rmses.append(rmse)\n",
    "                        avg_rmse = np.mean(rmses)\n",
    "                       \n",
    "\n",
    "                        if avg_rmse < best_rmse:\n",
    "                            best_rmse = avg_rmse\n",
    "                            model_params = (ne, lr, md, cw, cs, ss)\n",
    "                            print(f\"NEW BEST MODEL:\\n {model_params}: Avg RMSE: {avg_rmse:.4f}\")\n",
    "                        else:\n",
    "                            print(f\"Params: {ne, lr, md, cw, cs, ss} | Avg RMSE: {avg_rmse:.4f}\")\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0097780-b430-4b50-8f58-0be517a2198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define parameter grid\n",
    "possible_estimator = [500, 550, 600, 650, 750, 800, 850, 900, 950, 1000]\n",
    "possible_learning_rate = [0.04]\n",
    "possible_max_depth = [4]\n",
    "possible_child_weight = [1]\n",
    "possible_col_sample = [1]\n",
    "possible_subsample = [1]\n",
    "\n",
    "# Set up KFold\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "best_rmse = float('inf')\n",
    "model_params = None\n",
    "\n",
    "for ne in possible_estimator:\n",
    "    for lr in possible_learning_rate:\n",
    "        for md in possible_max_depth:\n",
    "            for cw in possible_child_weight:\n",
    "                for cs in possible_col_sample:\n",
    "                    for ss in possible_subsample:\n",
    "                        rmses = []\n",
    "                        for train_index, val_index in kf.split(X_train):\n",
    "                            X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "                            y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "                            # Scale the target\n",
    "                            scaler = MinMaxScaler()\n",
    "                            y_tr_scaled = scaler.fit_transform(y_tr.reshape(-1, 1)).ravel()\n",
    "\n",
    "                            # Train model\n",
    "                            model = xgb.XGBRegressor(\n",
    "                                objective='reg:logistic',\n",
    "                                booster='dart',\n",
    "                                colsample_bytree=cs,\n",
    "                                learning_rate=lr,\n",
    "                                max_depth=md,\n",
    "                                min_child_weight=cw,\n",
    "                                n_estimators=ne,\n",
    "                                subsample=ss,\n",
    "                                random_state=42\n",
    "                            )\n",
    "                            model.fit(X_tr, y_tr_scaled)\n",
    "\n",
    "                            # Predict and inverse scale\n",
    "                            y_pred_scaled = model.predict(X_val)\n",
    "                            y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()\n",
    "\n",
    "                            # Calculate RMSE\n",
    "                            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "                            rmses.append(rmse)\n",
    "\n",
    "                        avg_rmse = np.mean(rmses)\n",
    "                        print(f\"Params: {ne, lr, md, cw, cs, ss} | Avg RMSE: {avg_rmse:.4f}\")\n",
    "\n",
    "                        if avg_rmse < best_rmse:\n",
    "                            best_rmse = avg_rmse\n",
    "                            model_params = (ne, lr, md, cw, cs, ss)\n",
    "                            print(\"NEW BEST MODEL\")\n",
    "\n",
    "print(f\"\\nBest Parameters: {model_params} | Best CV RMSE: {best_rmse:.4f}\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
